{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/jack/Library/CloudStorage/GoogleDrive-limjackailjk@gmail.com/My Drive/UCSD/DSC/DSC180/ClimateBench - Plus/ClimateBench-Plus/DKL Gaussian Process/data/processed_data/'\n",
    "# datapath = 'G://My Drive//UCSD//DSC//DSC180//ClimateBench - Plus//ClimateBench-Plus//DKL Gaussian Process//data//processed_data//'\n",
    "simulations = ['ssp126', 'ssp370', 'ssp585', 'hist-GHG', 'hist-aer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenMappingWarningOnValuesAccess({'time': 251, 'longitude': 144, 'latitude': 96}) ssp126\n",
      "FrozenMappingWarningOnValuesAccess({'time': 251, 'longitude': 144, 'latitude': 96}) ssp370\n",
      "FrozenMappingWarningOnValuesAccess({'time': 251, 'longitude': 144, 'latitude': 96}) ssp585\n",
      "FrozenMappingWarningOnValuesAccess({'time': 165, 'longitude': 144, 'latitude': 96}) hist-GHG\n",
      "FrozenMappingWarningOnValuesAccess({'time': 165, 'longitude': 144, 'latitude': 96}) hist-aer\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for i, simu in enumerate(simulations):\n",
    "    input_name = 'inputs_' + simu + '.nc'\n",
    "    output_name = 'outputs_' + simu + '.nc'\n",
    "    # Just load hist data in these cases 'hist-GHG' and 'hist-aer'\n",
    "    if 'hist' in simu:\n",
    "        # load inputs \n",
    "        input_xr = xr.open_dataset(datapath + input_name)\n",
    "            \n",
    "        # load outputs                                                             \n",
    "        output_xr = xr.open_dataset(datapath + output_name).mean(dim='member')\n",
    "        output_xr = output_xr.assign({\"pr\": output_xr.pr * 86400, \"pr90\": output_xr.pr90 * 86400})\\\n",
    "                             .rename({'lon':'longitude', 'lat': 'latitude'})\\\n",
    "                             .transpose('time','latitude', 'longitude').drop(['quantile'])\n",
    "    \n",
    "    # Concatenate with historical data in the case of scenario 'ssp126', 'ssp370' and 'ssp585'\n",
    "    else:\n",
    "        # load inputs \n",
    "        input_xr = xr.open_mfdataset([datapath + 'inputs_historical.nc', datapath + input_name]).compute()\n",
    "            \n",
    "        # load outputs                                                             \n",
    "        output_xr = xr.concat([xr.open_dataset(datapath + 'outputs_historical.nc').mean(dim='member'),\n",
    "                               xr.open_dataset(datapath + output_name).mean(dim='member')],\n",
    "                               dim='time').compute()\n",
    "        output_xr = output_xr.assign({\"pr\": output_xr.pr * 86400,\"pr90\": output_xr.pr90 * 86400})\\\n",
    "                             .rename({'lon':'longitude', 'lat': 'latitude'})\\\n",
    "                             .transpose('time','latitude', 'longitude').drop(['quantile'])\n",
    "\n",
    "    print(input_xr.dims, simu)\n",
    "\n",
    "    # Append to list \n",
    "    X_train.append(input_xr)\n",
    "    Y_train.append(output_xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1074.172303244536, 1755.690699230666)\n",
      "(0.1927369743762821, 0.18457590641432994)\n",
      "(2.5623359997066755e-12, 2.250114566783271e-11)\n",
      "(1.4947905009818064e-13, 1.0313342554838387e-12)\n"
     ]
    }
   ],
   "source": [
    "# Compute mean/std of each variable for the whole dataset\n",
    "meanstd_inputs = {}\n",
    "len_historical = 165\n",
    "\n",
    "for var in ['CO2', 'CH4', 'SO2', 'BC']:\n",
    "    # To not take the historical data into account several time we have to slice the scenario datasets\n",
    "    # and only keep the historical data once (in the first ssp index 0 in the simus list)\n",
    "    array = np.concatenate([X_train[i][var].data for i in [0, 3, 4]] + \n",
    "                           [X_train[i][var].sel(time=slice(len_historical, None)).data for i in range(1, 3)])\n",
    "    print((array.mean(), array.std()))\n",
    "    meanstd_inputs[var] = (array.mean(), array.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input data \n",
    "X_train_norm = [] \n",
    "for i, train_xr in enumerate(X_train): \n",
    "    for var in ['CO2', 'CH4', 'SO2', 'BC']: \n",
    "        var_dims = train_xr[var].dims\n",
    "        train_xr=train_xr.assign({var: (var_dims, normalize(train_xr[var].data, var, meanstd_inputs))}) \n",
    "    X_train_norm.append(train_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(726, 4, 96, 144)\n",
      "(726, 1, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "var_to_predict =  'tas'\n",
    "# skip_historical set to (i < 2) because of the order of the scenario and historical runs in the X_train and Y_train lists.\n",
    "# In details: ssp126 0, ssp370 1 = skip historical part of the data, ssp585 2, hist-GHG 3 and hist-aer 4 = keep the whole sequence\n",
    "X_train_all = np.concatenate([input_for_training(X_train_norm[i], skip_historical=(i<2), len_historical=len_historical) for i in range(len(simulations))], axis = 0)\n",
    "Y_train_all = np.concatenate([output_for_training(Y_train[i], var_to_predict, skip_historical=(i<2), len_historical=len_historical) for i in range(len(simulations))], axis=0)\n",
    "# add a dimension to the output data\n",
    "Y_train_all = Y_train_all[..., np.newaxis]\n",
    "\n",
    "\n",
    "X_train_all = X_train_all.reshape(726, 4, 96, 144)\n",
    "Y_train_all = Y_train_all.reshape(726, 1, 96, 144)\n",
    "print(X_train_all.shape)\n",
    "print(Y_train_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_target_split(x, y, num_context, num_extra_target):\n",
    "    \"\"\"Given inputs x and their value y, return random subsets of points for\n",
    "    context and target. Note that following conventions from \"Empirical\n",
    "    Evaluation of Neural Process Objectives\" the context points are chosen as a\n",
    "    subset of the target points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Shape (batch_size, num_points, x_dim)\n",
    "\n",
    "    y : torch.Tensor\n",
    "        Shape (batch_size, num_points, y_dim)\n",
    "\n",
    "    num_context : int\n",
    "        Number of context points.\n",
    "\n",
    "    num_extra_target : int\n",
    "        Number of additional target points.\n",
    "    \"\"\"\n",
    "    batch_size, _, lat, lng = x.shape\n",
    "    x = x.reshape(batch_size, 4, lat*lng)\n",
    "    y = y.reshape(batch_size, 1, lat*lng)\n",
    "    num_points = x.shape[2]\n",
    "    # Sample locations of context and target points\n",
    "    locations = np.random.choice(num_points,\n",
    "                                 size=num_context + num_extra_target,\n",
    "                                 replace=False)\n",
    "    x_context = x[:, :, locations[:num_context]]\n",
    "    y_context = y[:, :, locations[:num_context]]\n",
    "    x_target = x[:, :, locations]\n",
    "    y_target = y[:, :, locations]\n",
    "\n",
    "    x_context = x_context.reshape(batch_size, 4, lat, lng)\n",
    "    y_context = y_context.reshape(batch_size, 1, lat, lng)\n",
    "    x_target = x_target.reshape(batch_size, 4, lat, lng)\n",
    "    y_target = y_target.reshape(batch_size, 1, lat, lng)\n",
    "    return x_context, y_context, x_target, y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 8712 into shape (726,4,96,144)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Context/Target set split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_context, Y_context, X_target, Y_target \u001b[38;5;241m=\u001b[39m \u001b[43mcontext_target_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_extra_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 34\u001b[0m, in \u001b[0;36mcontext_target_split\u001b[0;34m(x, y, num_context, num_extra_target)\u001b[0m\n\u001b[1;32m     31\u001b[0m x_target \u001b[38;5;241m=\u001b[39m x[:, :, locations]\n\u001b[1;32m     32\u001b[0m y_target \u001b[38;5;241m=\u001b[39m y[:, :, locations]\n\u001b[0;32m---> 34\u001b[0m x_context \u001b[38;5;241m=\u001b[39m \u001b[43mx_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m y_context \u001b[38;5;241m=\u001b[39m y_context\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m1\u001b[39m, lat, lng)\n\u001b[1;32m     36\u001b[0m x_target \u001b[38;5;241m=\u001b[39m x_target\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m4\u001b[39m, lat, lng)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 8712 into shape (726,4,96,144)"
     ]
    }
   ],
   "source": [
    "# Context/Target set split\n",
    "X_context, Y_context, X_target, Y_target = context_target_split(X_train_all, Y_train_all, num_context=3, num_extra_target=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Neural Process Arch\n",
    "- Encoder --> Takes context points x_i, y_i to r_i (deterministic path) and s_i (latent path)\n",
    "- **r_c, s_c** from context points representations aggregated by mean\n",
    "- Decoder --> Takes r_c, s_c, target points x_i to predict y_i\n",
    "\n",
    "Pytorch implementation --> https://github.com/EmilienDupont/neural-processes/blob/master/neural_process.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from model import TimeDistributed\n",
    "from np import Encoder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "- Input: x_i, y_i (context points)\n",
    "    - x_i: (726, 10, 96, 144, 4)\n",
    "    - y_i: (726, 1, 96, 144)\n",
    "- Output: r_i, s_i\n",
    "\n",
    "Plan to use LSTM/CNN network to encode the context points into the representations\n",
    "\n",
    "#### Changes after meeting\n",
    "- Reduce shape to (726, 96, 144, 4) and (726, 96, 144, 1) respectively since time covariance should not matter too much in this case,\n",
    "- Remove LSTM layer, since time slider shouldn't matter and would make the problem easier. \n",
    "- If doesn't work, we can flatten the latlng layer too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Maps an (x_i, y_i) pair to a representation r_i.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_dim : int\n",
    "        Dimension of output representation r.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=5, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(64, r_dim)\n",
    "\n",
    "    def forward(self, context_points):\n",
    "        \"\"\"\n",
    "        context_points : torch.Tensor\n",
    "            Shape (batch_size, 4 (aerosols), 96 (lat), 144 (lon))\n",
    "        \"\"\"\n",
    "        # context_points shape: [batch_size, channels, height, width] -> [batch_size, 5, 96, 144]\n",
    "        context_points = torch.relu(self.conv1(context_points))\n",
    "        context_points = self.pool(context_points)\n",
    "        context_points = torch.relu(self.conv2(context_points))\n",
    "        context_points = self.pool(context_points)\n",
    "        context_points = torch.relu(self.conv3(context_points))\n",
    "        context_points = self.global_pool(context_points)  # Reduce to [batch_size, 64, 1, 1]\n",
    "        context_points = torch.flatten(context_points, 1)  # Flatten to [batch_size, 64]\n",
    "        context_points = self.fc1(context_points)  # Map to [batch_size, r_dim]\n",
    "        return context_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(x, y):\n",
    "        \"\"\"Concatenate x and y along channel dimension.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape (batch_size, c, m, n).\n",
    "        y : torch.Tensor\n",
    "            Shape (batch_size, d, m, n).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape (batch_size, c + d, m, n).\n",
    "        \"\"\"\n",
    "        return torch.cat([x, y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([726, 4, 96, 144]) torch.Size([726, 1, 96, 144])\n"
     ]
    }
   ],
   "source": [
    "X_train_all = torch.tensor(X_train_all).float()\n",
    "Y_train_all = torch.tensor(Y_train_all).float()\n",
    "\n",
    "x_context_points = X_train_all.reshape(726, 4, 96, 144)\n",
    "y_context_points = Y_train_all.reshape(726, 1, 96, 144)\n",
    "print(x_context_points.shape, y_context_points.shape)\n",
    "\n",
    "encoder = Encoder(r_dim=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MuSigmaEncoder\n",
    "\n",
    "- Input: r_i, s_i\n",
    "    - r_i: Representation of context points (726, r_dim)\n",
    "    - s_i: Latent representation of context points (726, s_dim)\n",
    "\n",
    "- Output: mu, sigma\n",
    "    - mu: Mean of the distribution (726, s_i)\n",
    "    - sigma: Standard deviation of the distribution (726, s_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuSigmaEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Maps a representation r to mu and sigma which will define the normal\n",
    "    distribution from which we sample the latent variable z.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_dim : int\n",
    "        Dimension of output representation r.\n",
    "\n",
    "    z_dim : int\n",
    "        Dimension of latent variable z.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_dim, z_dim):\n",
    "        super(MuSigmaEncoder, self).__init__()\n",
    "\n",
    "        self.r_dim = r_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.r_to_hidden = nn.Linear(r_dim, r_dim)\n",
    "        self.hidden_to_mu = nn.Linear(r_dim, z_dim)\n",
    "        self.hidden_to_sigma = nn.Linear(r_dim, z_dim)\n",
    "\n",
    "    def forward(self, r):\n",
    "        \"\"\"\n",
    "        r : torch.Tensor\n",
    "            Shape (batch_size, r_dim)\n",
    "        \"\"\"\n",
    "        hidden = torch.relu(self.r_to_hidden(r))\n",
    "        mu = self.hidden_to_mu(hidden)\n",
    "        # Define sigma following convention in \"Empirical Evaluation of Neural\n",
    "        # Process Objectives\" and \"Attentive Neural Processes\"\n",
    "        sigma = 0.1 + 0.9 * torch.sigmoid(self.hidden_to_sigma(hidden))\n",
    "        return mu, sigma\n",
    "    \n",
    "\n",
    "mu_sigma_encoder = MuSigmaEncoder(r_dim=128, z_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 96, 144]) torch.Size([32, 1, 96, 144])\n",
      "torch.Size([32, 5, 96, 144])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "# Define the data loader\n",
    "data = DataLoader(list(zip(x_context_points, y_context_points)), batch_size=32, shuffle=True) \n",
    "# does batches make sense here? Cause it is training by time, so technically the order/sequence of the data matters, which would mean I add a dummy batch dimension to the data, to fit into the model for now?\n",
    "for x, y in data:\n",
    "    print(x.shape, y.shape)\n",
    "    context = torch.cat([x, y], dim=1) # [batch_size, 5, 96, 144] -> [batch_size, 4, 96, 144] + [batch_size, 1, 96, 144], concatenating along the input channels with the y output channel, everything else can stay the same as it is just the lat lng and number of year in batch\n",
    "    print(context.shape)\n",
    "    r_i = encoder(context)\n",
    "    print(r_i.shape)\n",
    "    r_i = torch.reshape(r_i, (32, 1, 128)) # [batch_size, num_points, r_dim] -> [batch_size, 1, r_dim] -> No use in choosing channel as not an image (may change to choose a specific lat lng maybe? Doesn't really make sense in my head but maybe it does in the model's)\n",
    "    r =  torch.mean(r_i, dim=1)\n",
    "    print(r.shape)\n",
    "    mu, sigma = mu_sigma_encoder(r) # If the before part makes sense, this should be fine.\n",
    "    print(mu.shape, sigma.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 96, 144])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = mu_sigma_encoder(r_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 64])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Maps target input x_target and samples z (encoding information about the\n",
    "    context points) to predictions y_target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_dim : int\n",
    "        Dimension of x values.\n",
    "\n",
    "    z_dim : int\n",
    "        Dimension of latent variable z.\n",
    "\n",
    "    h_dim : int\n",
    "        Dimension of hidden layer.\n",
    "\n",
    "    y_dim : int\n",
    "        Dimension of y values.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_dim, z_dim, h_dim, y_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.x_dim = x_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.y_dim = y_dim\n",
    "\n",
    "        layers = [nn.Linear(x_dim + z_dim, h_dim),\n",
    "                  nn.ReLU(inplace=True),\n",
    "                  nn.Linear(h_dim, h_dim),\n",
    "                  nn.ReLU(inplace=True),\n",
    "                  nn.Linear(h_dim, h_dim),\n",
    "                  nn.ReLU(inplace=True)]\n",
    "\n",
    "        self.xz_to_hidden = nn.Sequential(*layers)\n",
    "        self.hidden_to_mu = nn.Linear(h_dim, y_dim)\n",
    "        self.hidden_to_sigma = nn.Linear(h_dim, y_dim)\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        \"\"\"\n",
    "        x : torch.Tensor\n",
    "            Shape (batch_size, num_points, x_dim)\n",
    "\n",
    "        z : torch.Tensor\n",
    "            Shape (batch_size, z_dim)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Returns mu and sigma for output distribution. Both have shape\n",
    "        (batch_size, num_points, y_dim).\n",
    "        \"\"\"\n",
    "        batch_size, num_points, _ = x.size()\n",
    "        # Repeat z, so it can be concatenated with every x. This changes shape\n",
    "        # from (batch_size, z_dim) to (batch_size, num_points, z_dim)\n",
    "        z = z.unsqueeze(1).repeat(1, num_points, 1)\n",
    "        # Flatten x and z to fit with linear layer\n",
    "        x_flat = x.view(batch_size * num_points, self.x_dim)\n",
    "        z_flat = z.view(batch_size * num_points, self.z_dim)\n",
    "        # Input is concatenation of z with every row of x\n",
    "        input_pairs = torch.cat((x_flat, z_flat), dim=1)\n",
    "        hidden = self.xz_to_hidden(input_pairs)\n",
    "        mu = self.hidden_to_mu(hidden)\n",
    "        pre_sigma = self.hidden_to_sigma(hidden)\n",
    "        # Reshape output into expected shape\n",
    "        mu = mu.view(batch_size, num_points, self.y_dim)\n",
    "        pre_sigma = pre_sigma.view(batch_size, num_points, self.y_dim)\n",
    "        # Define sigma following convention in \"Empirical Evaluation of Neural\n",
    "        # Process Objectives\" and \"Attentive Neural Processes\"\n",
    "        sigma = 0.1 + 0.9 * F.softplus(pre_sigma)\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(x_dim=1, z_dim=64, h_dim=128, y_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m q_target \u001b[38;5;241m=\u001b[39m Normal(mu, sigma)\n\u001b[0;32m      4\u001b[0m z_sample \u001b[38;5;241m=\u001b[39m q_target\u001b[38;5;241m.\u001b[39mrsample()\n\u001b[1;32m----> 5\u001b[0m y_pred_mu, y_pred_sigma \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m p_y_pred \u001b[38;5;241m=\u001b[39m Normal(y_pred_mu, y_pred_sigma)\n",
      "File \u001b[1;32mc:\\Users\\limja\\anaconda3\\envs\\ClimateBench\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\limja\\anaconda3\\envs\\ClimateBench\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 52\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, z)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, z):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    x : torch.Tensor\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m        Shape (batch_size, num_points, x_dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    (batch_size, num_points, y_dim).\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     batch_size, num_points, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Repeat z, so it can be concatenated with every x. This changes shape\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# from (batch_size, z_dim) to (batch_size, num_points, z_dim)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, num_points, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "q_target = Normal(mu, sigma)\n",
    "z_sample = q_target.rsample()\n",
    "y_pred_mu, y_pred_sigma = decoder(x, z_sample)\n",
    "p_y_pred = Normal(y_pred_mu, y_pred_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClimateBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
