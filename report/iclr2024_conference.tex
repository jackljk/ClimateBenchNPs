
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tikz}

\title{Neural Processes for Climate Emulation}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Jack Kai Lim 
\thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.  Funding acknowledgements go at the end of the paper.} \\
Halıcıoğlu Data Science Institute\\
University of California, San Diego\\
\texttt{jklim@ucsd.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
   {Climate modeling has long been limited by the amount of resources needed to use legacy built Earth system models. As such, exploration into the many different and possible emission pathways have been relegated to one-dimensional impulse response or simple pattern scaling models, neither of which are capable of accounting for finer details when emulating the Shared Socioeconomic Pathways. This paper introduces a new benchmark using a (think of a word) model called a Neural Process in the hopes to improve upon the benchmarks that have been established in \cite{watson2022climatebench}. In the hopes that these Deep Learning models are capable of emulating the response of the full complexity of the Earth System Models to forcers using a fraction of the time and resources while also being more complex then simple pattern scaling models. These models would predict annualglobal mean global distributions of temperature, diurnal temperature range and precipitation given the emmisions and concentrations of Carbon Dioxide (C)$_2$, Methane (CH$_4$), Sulfur Dioxide (SO$_2$) and Black Carbon (BC).
    }
\end{abstract}

\section{Introduction}
Climate Scientist have already generated different emission pathways that are used to predict the future climate. These pathways are called the Shared Socioeconomic Pathways (SSPs). However, these models are computationally expensive and require a lot of resources to run, which limits the amount of exploration that can be done. Which is specifically important for policymakers as they need to assess different social and economic impacts under different emission scenarios to reduce the effect of climate change and achieve the goal. \cite{watson2022climatebench} introduced a benchmark using different machine learning models that emulate different emissions scenarios are able to generate predictions of global temperature, diurnal temperature, and precipitation(including extreme precipitation). This paper looks to build upon it by intorducing a new benchmark using a Neural Process model.

For the task at hand, we looked into a few implementations. A base Neural Process (NP) model \cite{gordon2020convolutional} which takes a sparse representation of the data and learns the distribution of the data. A Covolutional Neural Process (CNP) which introduces the use of Covolutional layer in the Neural Process, allowing the model to learn the spatial dependencies of the data and also a CNP which introduces the use of a Spherical Covolutional layer in the Neural Process, allowing the model to learn the spatial dependencies of the data in a spherical manner which fits the idea of the Earth being a sphere.

\begin{figure}
    \centering
     {{\includegraphics[width=5cm]{figure/input.png} }}%
     \qquad
     {{\includegraphics[width=6cm]{figure/output.png} }}%
     \caption{(a) Line Graphs of Input Variables from Multiple SSP (b) Map of Output Variables from SSP245}%
     \label{fig:example}%
\end{figure}


\section{Data}
Following the work of \cite{watson2022climatebench}, this paper will use the same training data from the Norwegian Earth System Model (NorESM2) which is generated data from simulations performed by the NorESM2 model. This was done as part of the sixth coupled model intercomparison project(CMIP6 ; Eyring et al.,2016 ). The data is used by the policymakers when deciding climate policies so that the emissions data that come from the NorESM2 and CMIP allow the improved ClimateBench Plus models to predict outcomes of different possible scenarios that align with the policymakers' want to reduce climate change. The data that is extracted from NorESM2 and CMIP are netcdfs which are multi-dimensional containing data on every latitude and longitude for the emissions and aerosols that we are looking at i.e Carbon Dioxide, Methane, Sulfur Dioxide, and Black Carbon and span from the 1850s to the end of 2100. 

The input variables include emission data of \textbf{CO$_{2}$}, \textbf{SO$_{2}$}, \textbf{CH$_{4}$}, and \textbf{Black Carbon} by different emission scenarios data and historical data. We took the global average of input variables CO$_{2}$ and CH$_{4}$ by year. We convert the units of SO$_{2}$ and Black Carbon into Tera gram and take the global sum. Through this process, we acquire the patterns of four different input variables from 2020 to 2100. The output variables are temperature (TAS), Precipitation (PR), 90th percentile precipitation (PR90), and daily diurnal temperature range (DTR). 

\subsection*{Data Preprocessing}
\label{sec:data_preprocessing}
For the base Neural Process we used a Sparse Representation of the data in order to reduce the data into 1 dimension. Where the context points are a mask of 10\% to 30\% of the training data from the geographical grid cells. The target points are the rest of the data. The data is then normalized to have a mean of 0 and a standard deviation of 1.

\begin{equation*}
    x \rightarrow (\text{lat}, \text{lon}, \text{time}, \text{aerosols input}) \quad y \rightarrow (\text{temperature}, \text{precipitation}, \text{DTR}, \text{PR90})
\end{equation*}

For the CNP models we use a multidimensional representation similar to the one in the Covolutional Neural Network baseline model in \cite{watson2022climatebench}. Where the dimensions are:

\begin{equation*}
    x \rightarrow (\text{time}, \text{aerosols input}, \text{lat}, \text{lon}) \quad y \rightarrow (\text{temperature}, \text{precipitation}, \text{DTR}, \text{PR90})
\end{equation*}

\section*{Neural Processes}
A Neural Process is a class of neural latent variable models which combines the best of both a Gaussian Process (GP) \cite*{rasmussen2006gaussian} and a Neural Network. The Neural Process (NP) \cite{garnelo2018neural} define a distribution over functions like GPs and are capable of rapid adaptation to new observations, and can also estimate the uncertainties. While at the same time are computationally efficient like Neural Networks and are able to adapt their their priors to the data, while as the same time also having the flexibility to model complex functions. 

A Neural Process is made up of two components, the encoder and the decoder. The encoder takes in the context points and encodes them into a latent representation. The decoder then takes the latent representation and the target points and decodes them into a distribution over the target points.

\begin{figure}[h!]
    \centering
    \includegraphics*[width=0.8\textwidth]{figure/np-model.png}
    \caption{Neural Process Model taken from \cite{garnelo2018neural}}
    \label{fig:np-model}
\end{figure}

With the flexibility of the Neural Process this allowed the construction of another variant of the Neural Process called the Convolutional Neural Process (CNP) \cite{gordon2020convolutional}. The CNP is a variant of the NP that uses a Convolutional Neural Network (CNN) to encode the context points. This allows the model to learn the spatial dependencies of the data. The CNP is able to learn the spatial dependencies of the data and is able to predict the target points based on the context points.

\section{Methods}
In this paper we used three different variations of the Neural Process Model to predict the global mean temperature, diurnal temperature range, and precipitation. The models are as follows:

\subsection*{Base Neural Process}
For a baseline model, we used a Neural Process model which takes in a sparse representation of the data, which reduces the higher dimensional spatial temporal data into a 1 dimensional representation. This simplifies the task removing the spatial dependencies and temporal dependencies of the data and making them independent of each other. This model is used to see how well the model can predict the data without the spatial and temporal dependencies.

The model takes in a sparse representation of the data \ref{sec:data_preprocessing} is passed through a linear Neural Network to encode the data into a latent representation with the context points. The latent representation is then passed through another linear Neural Network to decode the data into a distribution over the target points.

The architecture of the model is as follows:
% Add diagram of the model

\subsection*{Convolutional Neural Process}
The Convolutional Neural Process is a variant of the Neural Process that uses a Convolutional Neural Network to encode the context points. This allows the model to learn the spatial dependencies of the data. The model is able to learn the spatial dependencies of the data and is able to predict the target points based on the context points.

The model takes in a multidimensional representation of the data \ref{sec:data_preprocessing} is passed through a Convolutional Neural Network to encode the data into a latent representation with the context points. The latent representation is then passed through another Convolutional Neural Network to decode the data into a distribution over the target points.

The architecture of the model is as follows:

% Add diagram of the model

Details on the Neural Network layers can be found here 

\subsection*{Spherical Convolutional Neural Process}
Finally, we introduce the Spherical Convolutional Neural Process which is a variant of the Convolutional Neural Process that uses a Spherical Convolutional Neural Network to encode the context points. With the hopes to improve upon the Convolutional Neural Process by taking into account the spherical nature of the Earth when learning the spatial dependencies.

The model takes the same data as the Convolutional Neural Process and the architecture of the model is as follows:

% Add diagram of the model



\section{Evaluation against Benchmark Models}
\label{sec:evaluation_metric}
Following \cite{watson2022climatebench} we will also be using the $NRMSE_t$ from the paper which is defined as follows,
\begin{equation}
    NRMSE_s = \sqrt{\langle(|x_{i, j, t}|_t - |y_{i, j, t, n}|_{n, t})^2\rangle}/|\langle y_{i, j}\rangle|_{t, n}
\end{equation}
\begin{equation}
    NRMSE_g = \sqrt{|(\langle x_{i, j, t}\rangle - \langle|y_{i, j, t, n}|_n\rangle)^2|_t} / |\langle y_{i, j} \rangle|_{t, n}
\end{equation}
\begin{equation}
    NRMSE_t = NRMSE_s + \alpha \times NRMSE_g
\end{equation}

Where $NRMSE_s$ is the global mean root-mean squared error, and $NRMSE_g$ is $NRMSE$ in the global mean. The equation also includes a weighing function to take the decreasing grid-cell area towards the north and south poles which is defined as follows,
\begin{equation}
    \langle x_{i, j} \rangle = \frac{1}{N_{lat}N_{lon}}\sum_i^{N_{lat}}\sum_i^{N_{lon}} \cos(lat(i))x_{i, j}
\end{equation}
and the co-efficient $\alpha$ is chosen to be 5 from the ClimateBench paper, in order to provide equal weightage between the measures.

The reason, we are using this evaluation metric is to be able to compare directly the performances of our models against the models from the paper. And using the same evaluation metric will give us the most 1-1 comparison.

\section{Results}
Using the evaluation metric from \ref{sec:evaluation_metric} we are able to compare the performance of the models against the benchmark models from the ClimateBench paper. The results are as follows:

\begin{table}[t]
    \label{results-table}
    \begin{center}
        \begin{tabular}{lllll}
        \multicolumn{1}{c}{\bf Model}  &\multicolumn{1}{c}{\bf Temperature} & \multicolumn{1}{c}{\bf Precipitation} & \multicolumn{1}{c}{\bf DTR} & \multicolumn{1}{c}{\bf PR90}
        \\ \hline \\
        Base NP         & x \\
        CNP            & x \\
        Spherical CNP  & x \\
        GP             & x \\
        CNN             & x \\
        \end{tabular}
    \end{center}
    \caption{Comparison of the Neural Process Models against the Benchmark Models}
\end{table}

\section{Discussion}
neural processes benefit are does not require a lot of data, can be used for small datasets, can be used for high dimensional data, can be used for sequential data. Also good for few shot learning, works due to the context points.


\section{Conclusion}

\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}

\appendix
\section{Model Architectures}

\subsection{Convolutional Neural Process}


\begin{table}[t]
    \caption{Sample table title}
    \label{sample-table}
    \begin{center}
        \begin{tabular}{ll}
        \multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
        \\ \hline \\
        Dendrite         &Input terminal \\
        Axon             &Output terminal \\
        Soma             &Cell body (contains cell nucleus) \\
        \end{tabular}
    \end{center}
\end{table}


\subsection{Spherical Convolutional Neural Process}

\end{document}
