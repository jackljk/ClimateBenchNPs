{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = '/Users/jack/Library/CloudStorage/GoogleDrive-limjackailjk@gmail.com/My Drive/UCSD/DSC/DSC180/ClimateBench - Plus/ClimateBench-Plus/DKL Gaussian Process/data/processed_data/'\n",
    "datapath = 'G://My Drive//UCSD//DSC//DSC180//ClimateBench - Plus//ClimateBench-Plus//DKL Gaussian Process//data//processed_data//'\n",
    "simulations = ['ssp126', 'ssp370', 'ssp585', 'hist-GHG', 'hist-aer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen({'time': 251, 'longitude': 144, 'latitude': 96}) ssp126\n",
      "Frozen({'time': 251, 'longitude': 144, 'latitude': 96}) ssp370\n",
      "Frozen({'time': 251, 'longitude': 144, 'latitude': 96}) ssp585\n",
      "Frozen({'time': 165, 'longitude': 144, 'latitude': 96}) hist-GHG\n",
      "Frozen({'time': 165, 'longitude': 144, 'latitude': 96}) hist-aer\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for i, simu in enumerate(simulations):\n",
    "    input_name = 'inputs_' + simu + '.nc'\n",
    "    output_name = 'outputs_' + simu + '.nc'\n",
    "    # Just load hist data in these cases 'hist-GHG' and 'hist-aer'\n",
    "    if 'hist' in simu:\n",
    "        # load inputs \n",
    "        input_xr = xr.open_dataset(datapath + input_name)\n",
    "            \n",
    "        # load outputs                                                             \n",
    "        output_xr = xr.open_dataset(datapath + output_name).mean(dim='member')\n",
    "        output_xr = output_xr.assign({\"pr\": output_xr.pr * 86400, \"pr90\": output_xr.pr90 * 86400})\\\n",
    "                             .rename({'lon':'longitude', 'lat': 'latitude'})\\\n",
    "                             .transpose('time','latitude', 'longitude').drop(['quantile'])\n",
    "    \n",
    "    # Concatenate with historical data in the case of scenario 'ssp126', 'ssp370' and 'ssp585'\n",
    "    else:\n",
    "        # load inputs \n",
    "        input_xr = xr.open_mfdataset([datapath + 'inputs_historical.nc', datapath + input_name]).compute()\n",
    "            \n",
    "        # load outputs                                                             \n",
    "        output_xr = xr.concat([xr.open_dataset(datapath + 'outputs_historical.nc').mean(dim='member'),\n",
    "                               xr.open_dataset(datapath + output_name).mean(dim='member')],\n",
    "                               dim='time').compute()\n",
    "        output_xr = output_xr.assign({\"pr\": output_xr.pr * 86400,\"pr90\": output_xr.pr90 * 86400})\\\n",
    "                             .rename({'lon':'longitude', 'lat': 'latitude'})\\\n",
    "                             .transpose('time','latitude', 'longitude').drop(['quantile'])\n",
    "\n",
    "    print(input_xr.dims, simu)\n",
    "\n",
    "    # Append to list \n",
    "    X_train.append(input_xr)\n",
    "    Y_train.append(output_xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normaliza the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1074.172303244536, 1755.690699230666)\n",
      "(0.1927369743762821, 0.18457590641432994)\n",
      "(2.5623359997066755e-12, 2.250114566783271e-11)\n",
      "(1.4947905009818064e-13, 1.0313342554838387e-12)\n"
     ]
    }
   ],
   "source": [
    "# Compute mean/std of each variable for the whole dataset\n",
    "meanstd_inputs = {}\n",
    "len_historical = 165\n",
    "\n",
    "for var in ['CO2', 'CH4', 'SO2', 'BC']:\n",
    "    # To not take the historical data into account several time we have to slice the scenario datasets\n",
    "    # and only keep the historical data once (in the first ssp index 0 in the simus list)\n",
    "    array = np.concatenate([X_train[i][var].data for i in [0, 3, 4]] + \n",
    "                           [X_train[i][var].sel(time=slice(len_historical, None)).data for i in range(1, 3)])\n",
    "    print((array.mean(), array.std()))\n",
    "    meanstd_inputs[var] = (array.mean(), array.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input data \n",
    "X_train_norm = [] \n",
    "for i, train_xr in enumerate(X_train): \n",
    "    for var in ['CO2', 'CH4', 'SO2', 'BC']: \n",
    "        var_dims = train_xr[var].dims\n",
    "        train_xr=train_xr.assign({var: (var_dims, normalize(train_xr[var].data, var, meanstd_inputs))}) \n",
    "    X_train_norm.append(train_xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a given output variable (TAS) create the Train_X and Train_Y dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([726, 4, 96, 144])\n",
      "torch.Size([726, 1, 96, 144])\n"
     ]
    }
   ],
   "source": [
    "var_to_predict =  'tas'\n",
    "# skip_historical set to (i < 2) because of the order of the scenario and historical runs in the X_train and Y_train lists.\n",
    "# In details: ssp126 0, ssp370 1 = skip historical part of the data, ssp585 2, hist-GHG 3 and hist-aer 4 = keep the whole sequence\n",
    "X_train_all = np.concatenate([input_for_training(X_train_norm[i], skip_historical=(i<2), len_historical=len_historical) for i in range(len(simulations))], axis = 0)\n",
    "Y_train_all = np.concatenate([output_for_training(Y_train[i], var_to_predict, skip_historical=(i<2), len_historical=len_historical) for i in range(len(simulations))], axis=0)\n",
    "# add a dimension to the output data\n",
    "Y_train_all = Y_train_all[..., np.newaxis]\n",
    "\n",
    "\n",
    "X_train_all = X_train_all.reshape(726, 4, 96, 144)\n",
    "Y_train_all = Y_train_all.reshape(726, 1, 96, 144)\n",
    "X_train_all = torch.tensor(X_train_all).float()\n",
    "Y_train_all = torch.tensor(Y_train_all).float()\n",
    "print(X_train_all.shape)\n",
    "print(Y_train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current output explainations\n",
    "\n",
    "**X_train_all** : (726, 4, 96, 144)\n",
    "\n",
    "- 726 samples (years of training data)\n",
    "    - We are keeping each year independent of each other (no rolling window)\n",
    "- 4 input variable - Aerosols (CO2, CH4, SO2, BC)\n",
    "- 96 latitudes\n",
    "- 144 longitudes\n",
    "\n",
    "**Y_train_all** : (726, 1, 96, 144)\n",
    "\n",
    "- 726 samples (years of training data)\n",
    "    - We are keeping each year independent of each other (no rolling window)\n",
    "- 1 output variable - TAS\n",
    "    - *May add more output variables in the future*\n",
    "- 96 latitudes\n",
    "- 144 longitudes\n",
    "\n",
    "## Prepping the data for Neural Process\n",
    "\n",
    "1. First need to create a mask for the data (`create_context_target_mask` function in `utils.py`)\n",
    "    - This will be used to mask out the missing data\n",
    "    - Context Mask\n",
    "        - `num_context_range` : Number of context points to be used *In this case it is the number of lat/lng pixels to be non-hidden*\n",
    "    - Target Mask\n",
    "        - `num_extra_target_range` : Number of extra points that is shown in the target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 96, 144]) torch.Size([32, 1, 96, 144])\n"
     ]
    }
   ],
   "source": [
    "test_batch_X = X_train_all[0:32]\n",
    "test_batch_Y = Y_train_all[0:32]\n",
    "print(test_batch_X.shape, test_batch_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_lat_lng_mask(context_point_shape, num_context, num_extra_target):\n",
    "    aerosol_dim, lat_dim, lng_dim = context_point_shape\n",
    "    \n",
    "    # Empty mask\n",
    "    context_mask = torch.zeros((aerosol_dim, lat_dim, lng_dim))\n",
    "    target_mask = torch.zeros((aerosol_dim, lat_dim, lng_dim))\n",
    "\n",
    "    # random lat and lng\n",
    "    context_lat = np.random.randint(0, lat_dim, num_context)\n",
    "    context_lng = np.random.randint(0, lng_dim, num_context)\n",
    "    target_lat = np.random.randint(0, lat_dim, num_context + num_extra_target)\n",
    "    target_lng = np.random.randint(0, lng_dim, num_context + num_extra_target)\n",
    "    # set mask to 1\n",
    "    context_mask[:, context_lat, context_lng] = 1\n",
    "    target_mask[:, target_lat, target_lng] = 1\n",
    "    \n",
    "    return context_mask, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_target_mask(data_size, num_context, num_extra_target, batch_size, one_mask=True):\n",
    "    aerosol_dim, lat, lng = data_size\n",
    "    batch_context_mask = torch.zeros(batch_size, aerosol_dim, lat, lng)\n",
    "    batch_target_mask = torch.zeros(batch_size, aerosol_dim, lat, lng)\n",
    "    \n",
    "    if one_mask:\n",
    "        context_mask, target_mask = get_random_lat_lng_mask((1, lat, lng), num_context, num_extra_target)\n",
    "        for i in range(batch_size):\n",
    "            # apply the same mask to all the batch and all the aerosol variables\n",
    "            for j in range(aerosol_dim):\n",
    "                batch_context_mask[i, j] = context_mask\n",
    "                batch_target_mask[i, j] = target_mask\n",
    "        \n",
    "        return batch_context_mask, batch_target_mask\n",
    "    else:\n",
    "        for i in range(batch_size):\n",
    "            batch_context_mask[i], batch_target_mask[i] = get_random_lat_lng_mask((1, lat, lng), num_context, num_extra_target)\n",
    "        \n",
    "    return batch_context_mask, batch_target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 96, 144]) torch.Size([32, 4, 96, 144])\n"
     ]
    }
   ],
   "source": [
    "num_context_range = [2000, 8000]\n",
    "num_extra_target_range = [1000, 5000]\n",
    "\n",
    "num_context = np.random.randint(*num_context_range)\n",
    "num_extra_target = np.random.randint(*num_extra_target_range)\n",
    "\n",
    "data_size = (4, 96, 144)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "batch_context_mask, batch_target_mask = create_context_target_mask(data_size, num_context, num_extra_target, batch_size)\n",
    "print(batch_context_mask.shape, batch_target_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Process\n",
    "\n",
    "### Encoder\n",
    "Applies a CNN to the input data to get a representation of the input data (context points/target points)\n",
    "- Reduces the input data to a fixed size representation (Batch_size, aerosols_dim + variable_dim, lat, lng) --> (Batch_size, representation_dim)\n",
    "    - Representation_dim is set by user (In this case 128)\n",
    "- Applies a ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Maps an (x_i, y_i) pair to a representation r_i.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_dim : int\n",
    "        Dimension of output representation r.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=5, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(64, r_dim)\n",
    "\n",
    "    def forward(self, context_points):\n",
    "        \"\"\"\n",
    "        context_points : torch.Tensor\n",
    "            Shape (batch_size, 4 (aerosols), 96 (lat), 144 (lon))\n",
    "        \"\"\"\n",
    "        batch_size = context_points.shape[0]\n",
    "        x_dim = context_points.shape[1:]\n",
    "        # context_points shape: [batch_size, channels, height, width] -> [batch_size, 5, 96, 144]\n",
    "        context_points = torch.relu(self.conv1(context_points))\n",
    "        context_points = self.pool(context_points)\n",
    "        context_points = torch.relu(self.conv2(context_points))\n",
    "        context_points = self.pool(context_points)\n",
    "        context_points = torch.relu(self.conv3(context_points))\n",
    "        context_points = self.global_pool(context_points)  # Reduce to [batch_size, 64, 1, 1]\n",
    "        context_points = torch.flatten(context_points, 1)  # Flatten to [batch_size, 64]\n",
    "        context_points = self.fc1(context_points)  # Map to [batch_size, r_dim]\n",
    "        return context_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5, 96, 144])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep the context points and target points\n",
    "context_points_X = test_batch_X * batch_context_mask\n",
    "context_points_Y = test_batch_Y * batch_context_mask[:, 0:1, :, :] # doesn't matter which aerosol variable mask we use as they are all the same\n",
    "\n",
    "target_points_X = test_batch_X * batch_target_mask\n",
    "target_points_Y = test_batch_Y * batch_target_mask[:, 0:1, :, :]\n",
    "\n",
    "# get context and target points\n",
    "context_points = torch.cat([context_points_X, context_points_Y], dim=1)\n",
    "target_points = torch.cat([target_points_X, target_points_Y], dim=1)\n",
    "\n",
    "context_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128]) torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(r_dim=128)\n",
    "r_i_context = encoder(context_points)\n",
    "r_i_target = encoder(target_points)\n",
    "print(r_i_context.shape, r_i_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mu-Sigma Encoder\n",
    "Takes the representation from the encoder and outputs the mean and variance of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuSigmaEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Maps a representation r to mu and sigma which will define the normal\n",
    "    distribution from which we sample the latent variable z.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_dim : int\n",
    "        Dimension of output representation r.\n",
    "\n",
    "    z_dim : int\n",
    "        Dimension of latent variable z.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_dim, z_dim):\n",
    "        super(MuSigmaEncoder, self).__init__()\n",
    "\n",
    "        self.r_dim = r_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.r_to_hidden = nn.Linear(r_dim, r_dim)\n",
    "        self.hidden_to_mu = nn.Linear(r_dim, z_dim)\n",
    "        self.hidden_to_sigma = nn.Linear(r_dim, z_dim)\n",
    "\n",
    "    def forward(self, r):\n",
    "        \"\"\"\n",
    "        r : torch.Tensor\n",
    "            Shape (batch_size, r_dim)\n",
    "        \"\"\"\n",
    "        hidden = torch.relu(self.r_to_hidden(r))\n",
    "        mu = self.hidden_to_mu(hidden)\n",
    "        # Define sigma following convention in \"Empirical Evaluation of Neural\n",
    "        # Process Objectives\" and \"Attentive Neural Processes\"\n",
    "        sigma = 0.1 + 0.9 * torch.sigmoid(self.hidden_to_sigma(hidden))\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_context shape: torch.Size([32, 64])\n",
      "sigma_context shape: torch.Size([32, 64])\n",
      "mu_target shape: torch.Size([32, 64])\n",
      "sigma_target shape: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "# Setup mu and sigma encoder\n",
    "r_dim, z_dim = 128, 64\n",
    "mu_sigma_encoder = MuSigmaEncoder(r_dim, z_dim)\n",
    "\n",
    "# Get mu and sigma\n",
    "mu_context, sigma_context = mu_sigma_encoder(r_i_context)\n",
    "mu_target, sigma_target = mu_sigma_encoder(r_i_target)\n",
    "print(\"mu_context shape:\", mu_context.shape)\n",
    "print(\"sigma_context shape:\", sigma_context.shape)\n",
    "print(\"mu_target shape:\", mu_target.shape)\n",
    "print(\"sigma_target shape:\", sigma_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "Takes the sampled latent representation from the mu-sigma encoder and the target points x-points to output the predicted distributions mu and sigma which can be used to calculate the loss and make predictions.\n",
    "\n",
    "- xz_to_hidden : Takes the input pair (x, z context points) and outputs a hidden representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Maps target input x_target and samples z (encoding information about the\n",
    "    context points) to predictions y_target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, h_dim, y_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=5, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(64, r_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    \n",
    "        self.hidden_to_mu = nn.Linear(h_dim, y_dim)\n",
    "        self.hidden_to_sigma = nn.Linear(h_dim, y_dim)\n",
    "        \n",
    "    def forward(self, xz_input_pair):\n",
    "        \"\"\"\n",
    "        x : torch.Tensor\n",
    "            Shape (batch_size, num_points, x_dim)\n",
    "\n",
    "        z : torch.Tensor\n",
    "            Shape (batch_size, z_dim)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Returns mu and sigma for output distribution. Both have shape\n",
    "        (batch_size, num_points, y_dim).\n",
    "        \"\"\"\n",
    "        xz_input_pair = torch.relu(self.conv1(xz_input_pair))\n",
    "        xz_input_pair = self.pool(xz_input_pair)\n",
    "        xz_input_pair = torch.relu(self.conv2(xz_input_pair))\n",
    "        xz_input_pair = self.pool(xz_input_pair)\n",
    "        xz_input_pair = torch.relu(self.conv3(xz_input_pair))\n",
    "        xz_input_pair = self.global_pool(xz_input_pair)\n",
    "        xz_input_pair = torch.flatten(xz_input_pair, 1)\n",
    "        hidden = self.fc1(xz_input_pair)\n",
    "\n",
    "        mu = self.hidden_to_mu(hidden)\n",
    "        pre_sigma = self.hidden_to_sigma(hidden)\n",
    "\n",
    "        \n",
    "        # Define sigma following convention in \"Empirical Evaluation of Neural\n",
    "        # Process Objectives\" and \"Attentive Neural Processes\"\n",
    "        sigma = 0.1 + 0.9 * F.softplus(pre_sigma)\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to sample z from the distribution defined by mu and sigma\n",
    "# We sample z for both context and target points\n",
    "\n",
    "\n",
    "# Get context and target points Normal distributions\n",
    "import torch.distributions as D\n",
    "\n",
    "q_target = D.Normal(mu_target, sigma_target)\n",
    "q_context = D.Normal(mu_context, sigma_context)\n",
    "\n",
    "# Sample z\n",
    "z_sample_target = q_target.rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_sample_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 4 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# get the input for the decoder\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m xz_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_points_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_sample_target\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(xz_target\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 2"
     ]
    }
   ],
   "source": [
    "# Setup decoder\n",
    "decoder = Decoder(128, 128)\n",
    "\n",
    "# get the input for the decoder\n",
    "xz_target = torch.cat([target_points_X, z_sample_target], dim=-1)\n",
    "print(xz_target.shape)\n",
    "# Get predictions\n",
    "y_pred_mu, y_pred_sigma = decoder(xz_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClimateBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
